\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.1.1}{Machine Learning for Individualized Medicine}{chapter.1}% 2
\BOOKMARK [2][-]{subsection.1.1.1}{Machine Learning Modeling Pipelines}{section.1.1}% 3
\BOOKMARK [2][-]{subsection.1.1.2}{Outline of the Dissertation}{section.1.1}% 4
\BOOKMARK [1][-]{section.1.2}{Summary of Technical Contributions}{chapter.1}% 5
\BOOKMARK [-1][-]{part.1}{I Machine Learning for Individualized Medicine}{}% 6
\BOOKMARK [0][-]{chapter.2}{Estimating Treatment Effects from Observational Data}{part.1}% 7
\BOOKMARK [1][-]{section.2.1}{Background and Summary of Contributions}{chapter.2}% 8
\BOOKMARK [1][-]{section.2.2}{Related Work}{chapter.2}% 9
\BOOKMARK [1][-]{section.2.3}{Estimating CATE: Problem Setup}{chapter.2}% 10
\BOOKMARK [2][-]{subsection.2.3.1}{Potential Outcomes and Propensity Score}{section.2.3}% 11
\BOOKMARK [2][-]{subsection.2.3.2}{Bayesian Nonparametric Inference}{section.2.3}% 12
\BOOKMARK [2][-]{subsection.2.3.3}{Towards Principled CATE Estimation}{section.2.3}% 13
\BOOKMARK [1][-]{section.2.4}{Fundamental Limits of CATE Estimation}{chapter.2}% 14
\BOOKMARK [2][-]{subsection.2.4.1}{Optimal Minimax Rates}{section.2.4}% 15
\BOOKMARK [2][-]{subsection.2.4.2}{Backing off from ``Asymptopia"}{section.2.4}% 16
\BOOKMARK [1][-]{section.2.5}{CATE Estimation using Non-Stationary Gaussian Process Regression}{chapter.2}% 17
\BOOKMARK [2][-]{subsection.2.5.1}{Non-Stationary Gaussian Process Priors}{section.2.5}% 18
\BOOKMARK [2][-]{subsection.2.5.2}{Doubly-Robust Hyperparameters}{section.2.5}% 19
\BOOKMARK [1][-]{section.2.6}{Experiments}{chapter.2}% 20
\BOOKMARK [2][-]{subsection.2.6.1}{Learning Brownian Response Surfaces}{section.2.6}% 21
\BOOKMARK [2][-]{subsection.2.6.2}{The Infant Health and Development Program}{section.2.6}% 22
\BOOKMARK [0][-]{chapter.3}{Symbolic Approaches to Prognostic Model Interpretability}{part.1}% 23
\BOOKMARK [1][-]{section.3.1}{Symbolic Metamodeling}{chapter.3}% 24
\BOOKMARK [1][-]{section.3.2}{Metamodeling via Meijer G-functions}{chapter.3}% 25
\BOOKMARK [2][-]{subsection.3.2.1}{Parameterizing symbolic metamodels with Meijer G-functions}{section.3.2}% 26
\BOOKMARK [2][-]{subsection.3.2.2}{Optimizing symbolic metamodels via gradient descent}{section.3.2}% 27
\BOOKMARK [1][-]{section.3.3}{Related Work: Symbolic Metamodels as Gateways to Interpretation}{chapter.3}% 28
\BOOKMARK [1][-]{section.3.4}{Experiments}{chapter.3}% 29
\BOOKMARK [2][-]{subsection.3.4.1}{Learning Uni-variate Symbolic Expressions}{section.3.4}% 30
\BOOKMARK [2][-]{subsection.3.4.2}{ Instance-wise feature importance}{section.3.4}% 31
\BOOKMARK [0][-]{chapter.4}{Automated Prognostic Modeling}{part.1}% 32
\BOOKMARK [1][-]{section.4.1}{Overview of Related Literature}{chapter.4}% 33
\BOOKMARK [2][-]{subsection.4.1.1}{Automated ML and Bayesian Optimization}{section.4.1}% 34
\BOOKMARK [2][-]{subsection.4.1.2}{Causal Model Validation}{section.4.1}% 35
\BOOKMARK [1][-]{section.4.2}{AutoPrognosis: A System for Automated Prognostic Modeling}{chapter.4}% 36
\BOOKMARK [1][-]{section.4.3}{Pipeline Configuration via Structured Bayesian Optimization}{chapter.4}% 37
\BOOKMARK [2][-]{subsection.4.3.1}{The Pipeline Selection \046 Configuration Problem}{section.4.3}% 38
\BOOKMARK [2][-]{subsection.4.3.2}{Solving the PSCP via Bayesian Optimization}{section.4.3}% 39
\BOOKMARK [2][-]{subsection.4.3.3}{Bayesian Optimization via Structured Kernels}{section.4.3}% 40
\BOOKMARK [1][-]{section.4.4}{Validating Causal Models}{chapter.4}% 41
\BOOKMARK [2][-]{subsection.4.4.1}{Notation and Definitions}{section.4.4}% 42
\BOOKMARK [1][-]{section.4.5}{Causal Model Validation via Influence Functions}{chapter.4}% 43
\BOOKMARK [2][-]{subsection.4.5.1}{Step 1: Plug-in Estimation}{section.4.5}% 44
\BOOKMARK [2][-]{subsection.4.5.2}{Step 2: Unplugged Validation}{section.4.5}% 45
\BOOKMARK [2][-]{subsection.4.5.3}{Relation to Maximum Likelihood Estimation}{section.4.5}% 46
\BOOKMARK [2][-]{subsection.4.5.4}{Consistency and Efficiency}{section.4.5}% 47
\BOOKMARK [1][-]{section.4.6}{Calculating Influence Functions}{chapter.4}% 48
\BOOKMARK [1][-]{section.4.7}{Experiments}{chapter.4}% 49
\BOOKMARK [2][-]{subsection.4.7.1}{Experimental Setup}{section.4.7}% 50
\BOOKMARK [0][-]{chapter.5}{Deep Probabilistic Modeling of Longitudinal Data}{part.1}% 51
\BOOKMARK [1][-]{section.5.1}{Related Literature}{chapter.5}% 52
\BOOKMARK [1][-]{section.5.2}{Attentive State-Space Models}{chapter.5}% 53
\BOOKMARK [2][-]{subsection.5.2.1}{Structure of the EHR Data}{section.5.2}% 54
\BOOKMARK [2][-]{subsection.5.2.2}{Attentive State-Space Representation}{section.5.2}% 55
\BOOKMARK [2][-]{subsection.5.2.3}{Sequence-to-sequence Attention Mechanism}{section.5.2}% 56
\BOOKMARK [2][-]{subsection.5.2.4}{Why Attentive State Space Modeling?}{section.5.2}% 57
\BOOKMARK [1][-]{section.5.3}{Attentive Variational Inference}{chapter.5}% 58
\BOOKMARK [2][-]{subsection.5.3.1}{Variational Lower Bound}{section.5.3}% 59
\BOOKMARK [2][-]{subsection.5.3.2}{Attentive Inference Network}{section.5.3}% 60
\BOOKMARK [2][-]{subsection.5.3.3}{Learning with Stochastic Gradient Descent}{section.5.3}% 61
\BOOKMARK [1][-]{section.5.4}{Experiments}{chapter.5}% 62
\BOOKMARK [2][-]{subsection.5.4.1}{Understanding CF Progression Mechanisms}{section.5.4}% 63
\BOOKMARK [2][-]{subsection.5.4.2}{Predicting Prognosis}{section.5.4}% 64
\BOOKMARK [-1][-]{part.2}{II Application to Clinical Data}{}% 65
\BOOKMARK [0][-]{chapter.6}{Predicting Deterioration of Lung Function in Cystic Fibrosis}{part.2}% 66
\BOOKMARK [1][-]{section.6.1}{Background}{chapter.6}% 67
\BOOKMARK [1][-]{section.6.2}{Data and Experimental Setup}{chapter.6}% 68
\BOOKMARK [1][-]{section.6.3}{Training and Validation of AutoPrognosis}{chapter.6}% 69
\BOOKMARK [1][-]{section.6.4}{Results}{chapter.6}% 70
\BOOKMARK [2][-]{subsection.6.4.1}{Systematic Review of Existing Risk Scores}{section.6.4}% 71
\BOOKMARK [2][-]{subsection.6.4.2}{Diagnostic Accuracy Evaluation}{section.6.4}% 72
\BOOKMARK [2][-]{subsection.6.4.3}{Assessing the Clinical Utility of AutoPrognosis}{section.6.4}% 73
\BOOKMARK [2][-]{subsection.6.4.4}{Variable Importance Analysis}{section.6.4}% 74
\BOOKMARK [1][-]{section.6.5}{Discussion and Conclusions}{chapter.6}% 75
\BOOKMARK [0][-]{chapter.7}{Cardiovascular Disease Risk Prediction}{part.2}% 76
\BOOKMARK [1][-]{section.7.1}{Background}{chapter.7}% 77
\BOOKMARK [1][-]{section.7.2}{Data and Experimental Setup}{chapter.7}% 78
\BOOKMARK [2][-]{subsection.7.2.1}{Study Design and Participants}{section.7.2}% 79
\BOOKMARK [2][-]{subsection.7.2.2}{Outcome}{section.7.2}% 80
\BOOKMARK [2][-]{subsection.7.2.3}{Characteristics of the Study Population}{section.7.2}% 81
\BOOKMARK [2][-]{subsection.7.2.4}{Models Tested}{section.7.2}% 82
\BOOKMARK [1][-]{section.7.3}{Model Development using AutoPrognosis}{chapter.7}% 83
\BOOKMARK [1][-]{section.7.4}{Results}{chapter.7}% 84
\BOOKMARK [1][-]{section.7.5}{Discussion and Conclusions}{chapter.7}% 85
\BOOKMARK [0][-]{chapter.8}{Breast Cancer Prognostication and Treatment Benefit Prediction}{part.2}% 86
\BOOKMARK [1][-]{section.8.1}{Background}{chapter.8}% 87
\BOOKMARK [1][-]{section.8.2}{Data and Experimental Setup}{chapter.8}% 88
\BOOKMARK [2][-]{subsection.8.2.1}{Study Participants}{section.8.2}% 89
\BOOKMARK [2][-]{subsection.8.2.2}{Outcomes}{section.8.2}% 90
\BOOKMARK [2][-]{subsection.8.2.3}{Missing Data Imputation}{section.8.2}% 91
\BOOKMARK [1][-]{section.8.3}{Model Development using AutoPrognosis}{chapter.8}% 92
\BOOKMARK [1][-]{section.8.4}{Statistical Analysis}{chapter.8}% 93
\BOOKMARK [1][-]{section.8.5}{Results}{chapter.8}% 94
\BOOKMARK [1][-]{section.8.6}{Discussion and Conclusions}{chapter.8}% 95
\BOOKMARK [0][-]{chapter*.70}{References}{part.2}% 96
